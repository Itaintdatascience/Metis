{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a77ce4",
   "metadata": {},
   "source": [
    "# Web Scrape Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b8ab6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1424635272.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/hw/rwj0lwbx6g39k9_wsky35jkr0000gn/T/ipykernel_7550/1424635272.py\"\u001b[0;36m, line \u001b[0;32m86\u001b[0m\n\u001b[0;31m    opens = mainPage.find('div', class_=\"display--inline-block__373c0__2de_K margin-r1-5__373c0__1Vie3 border-color--default__373c0__2oFDT\").\u001b[0m\n\u001b[0m                                                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#making a chrome drive and adding chrome driver options\n",
    "options = Options()\n",
    "options.page_load_strategy = 'eager'\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "all_page_urls = []     #to save the page urls\n",
    "business_pages =[]     #to save the business page url\n",
    "\n",
    "search_item = 'restaurant'  #you can change what your wanna search for\n",
    "location = 'Oakland'    #change in which loaction you want to search\n",
    "\n",
    "base_url = \"https://www.yelp.com/search?find_desc=\" +search_item + \"&find_loc=\"+location+\"&start=\"  #main search page urls pattern\n",
    "\n",
    "print (base_url)\n",
    "\n",
    "def yelp_search_link():\n",
    "    for i in range(0,10,10):       #change here for your requirement\n",
    "        main_url = base_url+str(i)\n",
    "        all_page_urls.append(main_url)\n",
    "        print(main_url)\n",
    "yelp_search_link()\n",
    "\n",
    "def find_items_page():               #finding all business pages urls from main search page\n",
    "    for urls in all_page_urls:\n",
    "        browser.get(urls)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        time.sleep(0.30)\n",
    "        mains = soup.find_all('div', class_ = 'container__09f24__21w3G hoverable__09f24__2nTf3 margin-t3__09f24__5bM2Z margin-b3__09f24__1DQ9x padding-t3__09f24__-R_5x padding-r3__09f24__1pBFG padding-b3__09f24__1vW6j padding-l3__09f24__1yCJf border--top__09f24__8W8ca border--right__09f24__1u7Gt border--bottom__09f24__xdij8 border--left__09f24__rwKIa border-color--default__09f24__1eOdn')\n",
    "        main_url = 'https://www.yelp.com'\n",
    "        for main in mains:\n",
    "            a_tag = main.find('a', class_ = 'css-166la90').get('href')\n",
    "            a_tag_formated = main_url + str(a_tag)\n",
    "            items_pages.append(a_tag_formated)\n",
    "            print(a_tag_formated)\n",
    "find_items_page()\n",
    "\n",
    "Names = []            #Name of the business profile\n",
    "Reviews = []          #No of reviews recieved\n",
    "Open_Hour = []        #Open hours\n",
    "Price_range = []      #Price range\n",
    "Address = []          #Address of the business\n",
    "Websites = []         #Wbsites of the business\n",
    "Phones = []           #Phone number of the business\n",
    "\n",
    "\n",
    "def scrape_and_save():\n",
    "    for url in business_pages:\n",
    "        browser.get(url)\n",
    "        ss = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        mainPage = ss.find('div', class_ = 'main-content-wrap main-content-wrap--full')    #main content\n",
    "\n",
    "        try:\n",
    "            name = mainPage.find('h1', class_ = 'css-11q1g5y').get_text()\n",
    "            Names.append(name)\n",
    "        except AttributeError:\n",
    "            name = 'NUll'\n",
    "            Names.append(name)\n",
    "\n",
    "        try:\n",
    "            review = mainPage.find('span', class_ = 'css-bq71j2').get_text()\n",
    "            Reviews.append(review)\n",
    "        except AttributeError:\n",
    "            review = 'Null'\n",
    "            Reviews.append(review)\n",
    "\n",
    "        try:\n",
    "            price = mainPage.find('span', class_ = 'css-1xxismk').get_text()\n",
    "            Price_range.append(price)\n",
    "        except AttributeError:\n",
    "            price = 'Null'\n",
    "            Price_range.append(price)\n",
    "\n",
    "        try:\n",
    "            opens = mainPage.find('div', class_=\"display--inline-block__373c0__2de_K margin-r1-5__373c0__1Vie3 border-color--default__373c0__2oFDT\").\n",
    "            find_next('span', class_ = 'css-bq71j2').get_text()\n",
    "            Open_Hour.append(opens)\n",
    "        except AttributeError:\n",
    "            opens = 'Null'\n",
    "            Open_Hour.append(opens)\n",
    "\n",
    "        try:\n",
    "            address = mainPage.find('div', class_ = 'css-1vhakgw border--top__373c0__19Owr border-color--default__373c0__2oFDT').\n",
    "            find_next('p', class_ = 'css-1h1j0y3').find_next('p', class_ = 'css-e81eai').get_text()\n",
    "            Address.append(address)\n",
    "        except AttributeError:\n",
    "            address = 'Null'\n",
    "            Address.append(address)\n",
    "        except TypeError:\n",
    "            address = 'Null'\n",
    "            Address.append(address)\n",
    "\n",
    "        try:\n",
    "            website = mainPage.find('a', class_ = 'css-ac8spe').get_text()\n",
    "            website = 'https://www.'+ str(website)\n",
    "            Websites.append(website)\n",
    "        except AttributeError:\n",
    "            website = 'Null'\n",
    "            Websites.append(website)\n",
    "\n",
    "        try:\n",
    "            phone = mainPage.find('div', class_ = 'stickySidebar__373c0__3PY1o border-color--default__373c0__2oFDT').\n",
    "            find('p', class_ = 'css-1h1j0y3').find_next('p', class_ = 'css-1h1j0y3').get_text()\n",
    "            Phones.append(phone)\n",
    "        except AttributeError:\n",
    "            phone = 'Null'\n",
    "            Phones.append(phone)\n",
    "\n",
    "        print('Scraping Compeleted',url)\n",
    "\n",
    "    df = pd.DataFrame({'Names':Names, 'Price Range': Price_range, 'Reviews': Reviews,\n",
    "                       'Address':Address, 'Website': Websites,'Phone Number': Phones})  #making a pandas dataframe\n",
    "    \n",
    "    df.to_csv('Business Data.csv')   #Saving the data as csv\n",
    "    \n",
    "scrape_and_save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760398b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1424635272.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/hw/rwj0lwbx6g39k9_wsky35jkr0000gn/T/ipykernel_7550/1424635272.py\"\u001b[0;36m, line \u001b[0;32m86\u001b[0m\n\u001b[0;31m    opens = mainPage.find('div', class_=\"display--inline-block__373c0__2de_K margin-r1-5__373c0__1Vie3 border-color--default__373c0__2oFDT\").\u001b[0m\n\u001b[0m                                                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e4d882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hw/rwj0lwbx6g39k9_wsky35jkr0000gn/T/ipykernel_7550/473536422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'search_query' is not defined"
     ]
    }
   ],
   "source": [
    "search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669b20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
